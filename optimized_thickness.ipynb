{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook allows Glen's A to vary to optimize modeled ice thickness by minimizing the quadratic error between observed and modeled ice thickness (following height change corrections and in situ mass balance inversion)\n",
    "\n",
    "### named MONSTER by M. Zeuner (Mega Organized Numerical Script Transformation Executing Rapidly)\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from oggm import utils, workflow, tasks, graphics\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import salem\n",
    "import xarray as xr\n",
    "import oggm\n",
    "from oggm.workflow import execute_entity_task, gis_prepro_tasks, climate_tasks\n",
    "\n",
    "import oggm.cfg as cfg # could that cause problems?\n",
    "import gdal\n",
    "from PIL import Image as imagery\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the glacier by setting num to:\n",
    "\n",
    "- 0 for Kokanee\n",
    "- 1 for Haig\n",
    "- 2 for Conrad\n",
    "- 3 for W. Washmawapta (no DEM correction available)\n",
    "- 4 for Illecillewaet (not supported in this version of the script due to shapefile reasons)\n",
    "- 5 for Nordic (not supported in this version of the script due to shapefile reasons)\n",
    "- 6 for Zillmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected:  Conrad\n"
     ]
    }
   ],
   "source": [
    "# Here the num variable is set:\n",
    "num=2\n",
    "\n",
    "# A list with all the glacier names\n",
    "glacier = ['Kokanee', 'Haig', 'Conrad', 'Washmawapta', 'Illecillewaet', 'Nordic', 'Zillmer']\n",
    "\n",
    "# Just confirm that the correct one is selected for this run of the script\n",
    "print('You selected: ' , glacier[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File names settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with the names in the Randolf Glacier invetory (according to the glacier names above)\n",
    "rgi_list = ['RGI60-02.00147', 'RGI60-02.01857', 'RGI60-02.02171', 'RGI60-02.03688', 'RGI60-02.04264', 'RGI60-02.07780']\n",
    "\n",
    "# list with the names Lidar data (according to the glacier names above)\n",
    "dem = ['20160913_kokanee_dem1_clip_slave.tif', '20150912_haig_dem_master_clip.tif', '20160912_conrad_dem1_clip_slave.tif', 'not_assigned', \n",
    "       '170917_illecillewaet_dem1_clip_slave.tif', '20170927_nordic_dem1_clip_slave.tif', '160914_zillmer_dem2.tif']\n",
    "\n",
    "#products_directory (where the graphs and some numbers are saved for later usage)\n",
    "products= '/home/pelto/oggm_runs/products_opt/' + glacier[num] + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to run the OGGM using mass-balance correction and (if wished) the Lidar-DEM \n",
    "\n",
    "This is also a function that runs the OGGM on the selected glacier and returns a thickness map for it. It uses the mass-balance correction.\n",
    "\n",
    "In difference to the function above, this version does not use the SRTM DEM to run it but the more precise Lidar DEM which yields results closer to reality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_mb_grad_corr_dem(num, dem, glacier, name, parameter, best, use_dem_corr):\n",
    "    \"\"\"\n",
    "    :param num: number of selected glacier\n",
    "    :param dem: list with dem file names\n",
    "    :param glacier: the list with the glacier names\n",
    "    :param name: name of the parameter to be modified\n",
    "    :param parameter: value of the parameter to be modified\n",
    "    :param best: if TRUE, an extra save with prefix 'best' will be created\n",
    "    :param use_dem_correction: if TRUE, a Lidar DEM correction will be used\n",
    "    :type num: int\n",
    "    :type dem: str list\n",
    "    :type glacier: str list\n",
    "    :type name: str \n",
    "    :type parameter: float\n",
    "    :type best: boolean\n",
    "    :type use_dem_correction: boolean\n",
    "    :returns: distributed thickness\n",
    "    :rtype: 2D float array\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize OGGM and set up the run parameters --> Read the configuration file containing the runâ€™s parameters.\n",
    "    cfg.initialize(logging_level='WORKFLOW')\n",
    "\n",
    "    #num determines which gdir and gradient to use, refer to list below to select desired site\n",
    "    grad = [6.84, 9.8, 7.11, 7.95, 10.84, 6.01, 7.92] # mm w.e. m-1\n",
    "\n",
    "\n",
    "    # Get the RGI glaciers for the run.\n",
    "    rgi_list = ['RGI60-02.00147', 'RGI60-02.01857', 'RGI60-02.02171', 'RGI60-02.03411', 'RGI60-02.03688', 'RGI60-02.04264', 'RGI60-02.07780']\n",
    "    rgidf = utils.get_rgi_glacier_entities(rgi_list)\n",
    "\n",
    "    \n",
    "    ############################################################# here the DEM correction happens #########################################################\n",
    "    \n",
    "    if(use_dem_corr==True):\n",
    "    \n",
    "        custom_dem_path = dem[num]\n",
    "\n",
    "        WORKING_DIR2 = utils.gettempdir(glacier[num] + '_lidar_dem') # Let's make a working directory for this DEM \n",
    "        utils.mkdir(WORKING_DIR2, reset=True)\n",
    "        cfg.initialize(logging_level='WORKFLOW')\n",
    "        cfg.PATHS['working_dir'] = WORKING_DIR2\n",
    "\n",
    "        cfg.PATHS['dem_file'] = custom_dem_path\n",
    "        rgidf['DEM_SOURCE'] = 'USER'\n",
    "\n",
    "\n",
    "        cfg.PARAMS['smooth_window'] = 201.\n",
    "        #cfg.PARAMS['grid_dx_method'] = 'fixed'\n",
    "        #cfg.PARAMS['fixed_dx'] = dx\n",
    "        if glacier[num] == 'Nordic':\n",
    "            cfg.PARAMS['use_intersects'] = False\n",
    "        gdirs = workflow.init_glacier_regions(rgidf)\n",
    "\n",
    "\n",
    "        cfg.PATHS['working_dir'] = utils.get_temp_dir('test_thick' + glacier[num])\n",
    "        cfg.PARAMS['use_rgi_area'] = False\n",
    "        \n",
    "    else:\n",
    "        cfg.PARAMS['use_intersects'] = False\n",
    "        cfg.PARAMS['border'] = 10\n",
    "        cfg.PATHS['working_dir'] = utils.get_temp_dir('test_thick' + glacier[num])\n",
    "        cfg.PARAMS['use_rgi_area'] = False\n",
    "        cfg.PARAMS[name] = parameter\n",
    "        \n",
    "    ###########################################################################################################################\n",
    "    \n",
    "    cfg.PARAMS[name] = parameter\n",
    "    cfg.PARAMS['border'] = 10\n",
    "    \n",
    "    temporarily = [rgi_list[num]]\n",
    "    rgidf = utils.get_rgi_glacier_entities(temporarily)#[rgi_list[num]]) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "    gdirs = workflow.init_glacier_regions(rgidf)\n",
    "    workflow.gis_prepro_tasks(gdirs)\n",
    "    workflow.climate_tasks(gdirs)\n",
    "    workflow.inversion_tasks(gdirs)\n",
    "    workflow.execute_entity_task(tasks.distribute_thickness_per_altitude, gdirs);\n",
    "\n",
    "    gdir = gdirs[0]\n",
    "    tasks.init_present_time_glacier(gdir) ##This updates the mode_flowlines file and creates a stand-alone numerical glacier ready to run.\n",
    "\n",
    "    # Print the standard MB gradient from OGGM default\n",
    "    from oggm.core.massbalance import ConstantMassBalance, MultipleFlowlineMassBalance\n",
    "    # gdir = gdirs[num]\n",
    "\n",
    "    mb_mod = MultipleFlowlineMassBalance(gdir, use_inversion_flowlines=True, mb_model_class=ConstantMassBalance)\n",
    "    z, w, mb_on_z = mb_mod.get_annual_mb_on_flowlines()\n",
    "    mb_on_z *=  cfg.PARAMS['ice_density'] * cfg.SEC_IN_YEAR\n",
    "\n",
    "    # grad_line = np.polyfit(mb_on_z,z,2)\n",
    "    from scipy import stats \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(mb_on_z, z)\n",
    "    print(\"slope: %f    intercept: %f\" % (slope, intercept), \"  R-squared: %f\" % r_value**2)\n",
    "\n",
    "    # See the result of the inversion\n",
    "    workflow.execute_entity_task(tasks.distribute_thickness_per_altitude, gdirs);\n",
    "\n",
    "    ds_default = xr.open_dataset(gdir.get_filepath('gridded_data')).load()\n",
    "    ds_default.close() # I have the strange feeling that xarray sometimes won't re-read overwitten files (and we will overwrite it later)\n",
    "\n",
    "    ds_default = xr.open_dataset(gdir.get_filepath('gridded_data')).load()\n",
    "    ds_default.close() # I have the strange feeling that xarray sometimes won't re-read overwitten files (and we will overwrite it later)\n",
    "\n",
    "\n",
    "    # Let's apply a linear MB instead\n",
    "    from oggm.core.climate import apparent_mb_from_linear_mb\n",
    "\n",
    "\n",
    "    workflow.execute_entity_task(tasks.apparent_mb_from_linear_mb, gdir, mb_gradient=grad[num]);\n",
    "\n",
    "    from oggm.core.massbalance import LinearMassBalance\n",
    "\n",
    "    params = gdir.read_pickle('linear_mb_params')\n",
    "    print(params)\n",
    "\n",
    "    l_mb_mod = LinearMassBalance(params['ela_h'], grad=params['grad'])\n",
    "    l_mb_on_z = l_mb_mod.get_annual_mb(z) * cfg.PARAMS['ice_density'] * cfg.SEC_IN_YEAR\n",
    "\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(mb_on_z, z)\n",
    "    print(\"slope default: %f    intercept: %f\" % (slope, intercept), \"  R-squared: %f\" % r_value**2)\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(l_mb_on_z, z)\n",
    "    print(\"slope: %f    intercept: %f\" % (slope, intercept), \"  R-squared: %f\" % r_value**2)\n",
    "\n",
    "    ds_new = xr.open_dataset(gdir.get_filepath('gridded_data')).load()\n",
    "    ds_new.close() \n",
    "   \n",
    "\n",
    "    ########### gather more detailed information about the glacier ##############\n",
    "    df  = utils.compile_glacier_statistics(gdirs, inversion_only=True)\n",
    "    volume=df['inv_volume_km3']\n",
    "    \n",
    "    mfl=gdir.read_pickle('model_flowlines')\n",
    "    thickness= mfl[-1].surface_h - mfl[-1].bed_h\n",
    "    thickness=thickness[thickness>0].mean()\n",
    "    \n",
    "    ############## write it into txt file: #################\n",
    "    \n",
    "    if(best):\n",
    "        file= open(products+'best_dem_corr_run_of_'+glacier[num]+'_with_modified_' + name+'.txt', mode='w')\n",
    "    else:\n",
    "        file= open(products+'dem_corr_run_of_'+glacier[num]+'_with_modified_' + name+'.txt', mode='w')\n",
    "    \n",
    "    file.writelines(['Run of the DEM corrected model on ' + glacier[num]+' on ', str(datetime.datetime.now()), '\\n'])\n",
    "    file.write('parameter modified: '+name+'\\n')\n",
    "    file.write('parameter value: '+str(parameter)+'\\n')\n",
    "    file.write('glacier total volume: '+str(volume)+' km^3 \\n \\n \\n')\n",
    "    file.write('mean thickness value: '+str(thickness)+' m \\n')\n",
    "    file.close()\n",
    "    ##########################################################\n",
    "    \n",
    "    return ds_new.distributed_thickness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing DEM-corrected model with non-DEM-corrected model:\n",
    "\n",
    "- first we run the 'new_mb_grad' function\n",
    "- then we run the 'new_mb_grad_corr_dem' function\n",
    "- and then we subtract the thickness maps and can see where the usage of Lidar data actually impacted the outcome of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-15 07:51:30: oggm.cfg: Using configuration file: /home/pelto/anaconda2/envs/oggm_env/lib/python3.6/site-packages/oggm/params.cfg\n",
      "2019-11-15 07:51:32: oggm.workflow: Execute entity task glacier_masks on 1 glaciers\n",
      "2019-11-15 07:51:32: oggm.workflow: Multiprocessing: using all available processors (N=8)\n",
      "2019-11-15 07:51:32: oggm.core.gis: KeyError occurred during task glacier_masks on RGI60-02.02171: 'topo_valid_mask'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'topo_valid_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/pelto/anaconda2/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/pelto/anaconda2/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/home/pelto/anaconda2/envs/oggm_env/lib/python3.6/site-packages/oggm/workflow.py\", line 92, in __call__\n    return call_func(gdir, **self.out_kwargs)\n  File \"/home/pelto/anaconda2/envs/oggm_env/lib/python3.6/site-packages/oggm/utils/_workflow.py\", line 447, in _entity_task\n    out = task_func(gdir, **kwargs)\n  File \"/home/pelto/anaconda2/envs/oggm_env/lib/python3.6/site-packages/oggm/core/gis.py\", line 766, in glacier_masks\n    valid_mask = nc.variables['topo_valid_mask'][:]\nKeyError: 'topo_valid_mask'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-a1e8f6b02dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run the model without DEM correction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnew_mb_gradient\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnew_mb_grad_corr_dem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglacier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ice_density'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# plot it as a map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnew_mb_gradient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d150585b27e6>\u001b[0m in \u001b[0;36mnew_mb_grad_corr_dem\u001b[0;34m(num, dem, glacier, name, parameter, best, use_dem_corr)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mrgidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rgi_glacier_entities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemporarily\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[rgi_list[num]]) !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mgdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_glacier_regions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgis_prepro_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclimate_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mworkflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minversion_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oggm_env/lib/python3.6/site-packages/oggm/workflow.py\u001b[0m in \u001b[0;36mgis_prepro_tasks\u001b[0;34m(gdirs)\u001b[0m\n\u001b[1;32m    363\u001b[0m     ]\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtask_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mexecute_entity_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oggm_env/lib/python3.6/site-packages/oggm/workflow.py\u001b[0m in \u001b[0;36mexecute_entity_task\u001b[0;34m(task, gdirs, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_multiprocessing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mmppool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_mp_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONFIG_MODIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmppool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgdirs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         '''\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    642\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'topo_valid_mask'"
     ]
    }
   ],
   "source": [
    "# run the model without DEM correction\n",
    "new_mb_gradient= new_mb_grad_corr_dem(num, dem, glacier, 'ice_density', 900, False, False)\n",
    "\n",
    "# plot it as a map\n",
    "new_mb_gradient.plot()\n",
    "plt.title(glacier[num]+' standard settings thickness map')\n",
    "# and save it\n",
    "plt.savefig('/home/pelto/Desktop/ice_thick/products'+'standard_map_'+ glacier[num]+'.png', dpi=100)\n",
    "\n",
    "# replace 'nan' by  0\n",
    "new_mb_gradient=new_mb_gradient.fillna(0)\n",
    "\n",
    "if glacier[num]=='Washmawapta':\n",
    "    # make a copy for comparison reasons later on\n",
    "    new_mb_gradient_corr_dem=new_mb_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model with DEM correction\n",
    "new_mb_gradient_corr_dem= new_mb_grad_corr_dem(num, dem, glacier, 'ice_density', 900, False, True)\n",
    "\n",
    "# plot it as a map\n",
    "new_mb_gradient_corr_dem.plot()\n",
    "plt.title(glacier[num]+' DEM corrected Thickness map')\n",
    "\n",
    "# and save it\n",
    "plt.savefig(products+'dem_corr_standard_map_'+ glacier[num]+'.png', dpi=100)\n",
    "\n",
    "# replace 'nan' by  0\n",
    "new_mb_gradient_corr_dem=new_mb_gradient_corr_dem.fillna(0)\n",
    "\n",
    "# make a copy for comparison reasons later on\n",
    "new_mb_gradient_corr_dem_copy=new_mb_gradient_corr_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the actual differencing and plotting\n",
    "(new_mb_gradient_corr_dem-new_mb_gradient).plot()\n",
    "\n",
    "# label it, save it\n",
    "plt.title(glacier[num]+' Difference DEM corrected tickness less standard DEM')\n",
    "plt.savefig(products+'difference_dem_correction_'+ glacier[num]+'.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter optimization\n",
    "\n",
    "We want to run the Model with different values for a certain parameter. Therefore we define a few functions that will iterate over a sequenze of paramter values and allow us to compare the outcome to the observation data by displaying their respective squared residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_parameter(num,dem, glacier, name, parameter):\n",
    "    \"\"\"\n",
    "    :param num: number of selected glacier\n",
    "    :param dem: list with dem file names\n",
    "    :param glacier: the list with the glacier names\n",
    "    :param name: name of the parameter to be modified\n",
    "    :param parameter: value of the parameter to be modified\n",
    "    :type num: int\n",
    "    :type dem: str list\n",
    "    :type glacier: str list\n",
    "    :type name: str \n",
    "    :type parameter: float\n",
    "    :returns: distributed thickness\n",
    "    :rtype: 2D float array\n",
    "    \"\"\"\n",
    "    \n",
    "    # just to be 100% sure, we are setting the most common parameters to their presettings in order to only vary the desired parameter\n",
    "    \n",
    "    cfg.PARAMS['ice_density'] = 900\n",
    "    cfg.PARAMS['trapezoid_lambdas'] = 0.2\n",
    "    cfg.PARAMS['mixed_min_shape'] = 0.001\n",
    "    cfg.PARAMS['downstream_min_shape'] = 0.0001\n",
    "    cfg.PARAMS['mu_star_halfperiod'] = 15\n",
    "    cfg.PARAMS['tstar_search_glacierwide'] = False\n",
    "    cfg.PARAMS['border'] = 10\n",
    "    cfg.PARAMS['glen_a'] = 2.4e-24\n",
    "    cfg.PARAMS['inversion_glen_a'] = 2.4e-24\n",
    "    cfg.PARAMS['default_parabolic_bedshape'] = 0.003\n",
    "    cfg.PARAMS['use_shape_factor_for_fluxbasedmodel'] = ''\n",
    "    \n",
    "    #change the parameter (not sure, whether it has any effect here...)\n",
    "    cfg.PARAMS[name] = parameter\n",
    "\n",
    "    # run the model (in this case with DEM correction)\n",
    "    outcome=new_mb_grad_corr_dem(num, dem, glacier, name, parameter, False, use_dem_correction).fillna(0)\n",
    "\n",
    "    #return the thickness distribution\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# deletes the rows and lines that do only carry zeros for the sake of getting the right resolution \n",
    "# in order to rasterize the observation data to the same resolution and getting perfectly fitting arrays\n",
    "def delete_nodata(data):\n",
    "    \"\"\"\n",
    "    :param data: distributed thickness with 'nan' or '0' in it\n",
    "    :type data: 2D floar array\n",
    "    :returns: distributed thickness\n",
    "    :rtype: 2D float array\n",
    "    \"\"\"\n",
    "    \n",
    "    # get a numpy array out of it\n",
    "    data=data.values\n",
    "\n",
    "    #get the spots were actual values are\n",
    "    coordinates=np.nonzero(data)\n",
    "    \n",
    "    # create a fresh array of the minimal shape to contain all non-zero values\n",
    "    result=np.zeros(((1+np.max(coordinates[0])-np.min(coordinates[0])) ,(1+np.max(coordinates[1])-np.min(coordinates[1]))))\n",
    "\n",
    "    # fill it with the values\n",
    "    for i in range(0, len(coordinates[0])):\n",
    "        result[coordinates[0][i]-np.min(coordinates[0])][coordinates[1][i]-np.min(coordinates[1])]=data[coordinates[0][i]][coordinates[1][i]]\n",
    "    \n",
    "    # flip it and rotate it by pi\n",
    "    return np.flip(np.rot90(result,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple function to open the observation data and return it as an array\n",
    "def read_obs_data(path):\n",
    "    \"\"\"\n",
    "    :param path: distributed thickness with 'nan' or '0' in it\n",
    "    :type path: str\n",
    "    :returns: measurement points as an array\n",
    "    :rtype: 2D float array\n",
    "    \"\"\"\n",
    "    src_obs = gdal.Open(path)\n",
    "    return src_obs.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We open the observation data for the respective glacier and print out the shape and compare it with the shape of the OGGM:\n",
    "\n",
    "obs_data = read_obs_data('/home/pelto/oggm_runs/OGGM/MONSTER_project/obs_data/' +glacier[num]+'.tif')\n",
    "\n",
    "if obs_data.shape == delete_nodata(new_mb_gradient_corr_dem).shape:\n",
    "    print('Fantanstic, bot arrays have the same shape of: ' ,obs_data.shape )\n",
    "else:\n",
    "    print('Oh, Oh! Something went wrong because the observation data has the shape ' ,obs_data.shape , ' and the OGGM out put has a shape of: ' ,delete_nodata(new_mb_gradient_corr_dem).shape )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layover-Control\n",
    "\n",
    "This is a checking tool for adjusting the orientation of the observation data with respect to the model shapefile (in order to make it fit, we had to flip and rotate it in the 'delete_nodata' function). The resolution is not great but is should give an optical feedback on the fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the delete_nodata function on one of the recent outputs and save it in a temporay variable\n",
    "temp=delete_nodata(new_mb_gradient_corr_dem)\n",
    "\n",
    "# get its shape\n",
    "h,w = temp.shape\n",
    "\n",
    "# create a new array with zeros and of same size\n",
    "data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "# and get the data point coordinates\n",
    "nonzero=np.nonzero(temp)\n",
    "\n",
    "# run through the OGGM output and write into the array as RED color code\n",
    "for i in range(0,len(nonzero[0])):\n",
    "    data[nonzero[0][i]][nonzero[1][i]]= [temp[nonzero[0][i]][nonzero[1][i]], 0, 0]\n",
    "    \n",
    "# run through the observation data and write into the array as GREEN color code\n",
    "for i in range(0,len(np.nonzero(obs_data)[0])):\n",
    "    data[np.nonzero(obs_data)[0][i]][np.nonzero(obs_data)[1][i]]= [0, obs_data[np.nonzero(obs_data)[0][i]][np.nonzero(obs_data)[1][i]], 0]\n",
    "    \n",
    "# save and show\n",
    "img = imagery.fromarray(data, 'RGB')\n",
    "img.save(products+ 'overlay_test_'+ glacier[num]+ '.png')\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=products+'overlay_test_'+ glacier[num]+ '.png', width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Error\n",
    "\n",
    "\n",
    "We want a function that gives us the accumulated quadratic residuals of the observation data compared to the OGGM output. Because we may have very few points that are assigned a measurement but do not locate on the OGGM glacier, we have to do a little extra: We count those pixels, print their share on the entire quadratic errors and subtract their errors from the result in order not to confuse the optimization process later on. However, their share usually is below 1-2% - their impact therefore limited. This is only done for checking and consistency reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_errors(obs_data, mesharray):\n",
    "    \"\"\"\n",
    "    :param obs_data: array with measured values on respective spots\n",
    "    :param mesharray: distributed thickness of the model output (should have same shape as obs_data)\n",
    "    :type obs_data: 2D float array\n",
    "    :type mesharray: 2D float array\n",
    "    :returns: quadrativc error (problems corrected)\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "    # counts number of \"problematic\" pixels\n",
    "    count=0\n",
    "    \n",
    "    # coordinates of the data points\n",
    "    coordinates=np.nonzero(obs_data)\n",
    "    \n",
    "    # accumulated 'problematic pixel' quadratic error\n",
    "    problems=0\n",
    "    \n",
    "    # total accumulated quadratic error\n",
    "    err=0\n",
    "\n",
    "    # we go through all the measured points and accumulate the squared differences to the OGGM at that point\n",
    "    for i in range(0,len(coordinates[0])):\n",
    "        \n",
    "        # if however, the OGGM shows a thickness of zero there, this seems to be a \"problematic\" pixel \n",
    "        if mesharray[coordinates[0][i]][coordinates[1][i]]==0:\n",
    "            \n",
    "            # add to problems share\n",
    "            problems=problems+obs_data[coordinates[0][i]][coordinates[1][i]]**2\n",
    "            \n",
    "            # increment problem number\n",
    "            count=count+1\n",
    "        \n",
    "        # add squared difference\n",
    "        err=err+(obs_data[coordinates[0][i]][coordinates[1][i]]-mesharray[coordinates[0][i]][coordinates[1][i]])**2\n",
    "   \n",
    "    # outprint of details on \"problematic\" pixels\n",
    "    print('found ', count , ' problem(s) within a total number of data point of: ', len(coordinates[0]), ' problem share ', problems/err,)\n",
    "    \n",
    "    print('corrected quadratic error is: ', err-problems)\n",
    "    return (err-problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that runs the (DEM-corrected) OGGM and uses the quadratic_errors function to return the quadratic errors\n",
    "def master_analysis(name, parameter, obs_data, glacier, num):\n",
    "    \"\"\"\n",
    "    :param name: name of the parameter to be modified\n",
    "    :param parameter: value of the parameter to be modified\n",
    "    :param obs_data: measured data points\n",
    "    :param glacier: the list with the glacier names\n",
    "    :param num: number of selected glacier\n",
    "    :type name: str\n",
    "    :type parameter: float\n",
    "    :type obs_data: 2D float array\n",
    "    :type glacier: str list\n",
    "    :type num: int\n",
    "    :returns: quadratic errors\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    quadmesh= run_with_parameter(num, dem, glacier, name, parameter)\n",
    "    mesharray = delete_nodata(quadmesh)\n",
    "    \n",
    "    return quadratic_errors(obs_data, mesharray)\n",
    "\n",
    "# this function takes in the name of the parameter that is to be modified and a float list of the values for whose the OGGM is \n",
    "# to be run and the quadratic errors to be calculated. It returns an array with those values and their respective quadratic errors\n",
    "def optimize(name, values, obs_data, glacier, num):\n",
    "    \"\"\"\n",
    "    :param name: name of the parameter to be modified\n",
    "    :param values: values of the parameter to be modified\n",
    "    :param obs_data: measured data points\n",
    "    :param glacier: the list with the glacier names\n",
    "    :param num: number of selected glacier\n",
    "    :type name: str\n",
    "    :type values: float list\n",
    "    :type obs_data: 2D float array\n",
    "    :type glacier: str list\n",
    "    :type num: int\n",
    "    :returns: [values, quad_errors]\n",
    "    :rtype: float array\n",
    "    \"\"\"\n",
    "    \n",
    "    # here we store the original parameter value\n",
    "    temp= cfg.PARAMS[name]\n",
    "    \n",
    "    #an array to store the quadratic errors in\n",
    "    quad_errors=[]\n",
    "    for i in range(0,len(values)):\n",
    "        quad_errors.append(master_analysis(name, values[i], obs_data, glacier, num))\n",
    "        \n",
    "    # and here we reset it to the default value\n",
    "    cfg.PARAMS[name] = temp\n",
    "    \n",
    "    return [values, quad_errors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the parameter, interval and number of points that you want to get the quadratic error from \n",
    "\n",
    "The parameter intervall will be a linearly spaced sequence from min_value to max_value with number_of_steps steps.\n",
    "\n",
    "Also, choose, whether you prefer to run the iteration with the DEM correction. In the most cases it is strongly recommended to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_name='inversion_glen_a'\n",
    "max_value=0.1e-24\n",
    "min_value=54e-24\n",
    "number_of_steps=10\n",
    "\n",
    "use_dem_correction=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual iteration takes place here\n",
    "\n",
    "%%capture supresses the output, which is quite annoying if the OGGM runs several dozen times. But if you want to watch it work, go for it and delete that line.\n",
    "\n",
    "Apart from that, we basically run the optimize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "to_plot=optimize(parameter_name,np.linspace(min_value, max_value, number_of_steps), obs_data ,glacier, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot the quadratic errors as a function of the parameter values. We also print out the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['axes.titlepad'] = 30\n",
    "plt.plot(to_plot[0],to_plot[1],linestyle='--', marker='o', color='b')\n",
    "plt.xlabel('value of '+parameter_name)\n",
    "plt.ylabel('pointwise accumulated quadratic discrepancies [mÂ²]')\n",
    "plt.title('Quadratic errors of depth in dependence of ' +parameter_name)\n",
    " \n",
    "# save it\n",
    "plt.savefig(products+'quadratic_errors_'+parameter_name+'_from_'+str(min_value)+'_to_'+str(max_value)+'_'+ glacier[num]+'.png', dpi=100)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#small minimum function\n",
    "x=0\n",
    "for i in range(0,len(to_plot[1])):\n",
    "    if to_plot[1][i]==np.min(to_plot[1]):\n",
    "        x=i\n",
    "\n",
    "# print out\n",
    "print('Minimal value is '+str(np.min(to_plot[1]))+ ' at ' + parameter_name+' = ' +str(np.round(to_plot[0][x],decimals=28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep analysis of best parameter value\n",
    "\n",
    "Enter the value of the given Paramter, that yields a minimum in quadratic errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the minimum from above\n",
    "#best_value=to_plot[1][x]\n",
    "\n",
    "# select it manually\n",
    "best_value=8.095e-24  #1.417e-25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the model with the best parameter value to create seperate saves and a deep analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model= new_mb_grad_corr_dem(num, dem, glacier, parameter_name, best_value, True, False)\n",
    "\n",
    "# ds_new.distributed_thickness.plot()\n",
    "# best_model.plot()\n",
    "plt.title(glacier[num]+' best approximation thickness map ' + parameter_name + ' = ' +str(best_value))\n",
    "plt.savefig(products+'dem_corr_best_map_'+ glacier[num]+'.png', dpi=100)\n",
    "#best_model=new_mb_gradient_corr_dem.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save\n",
    "(best_model-new_mb_gradient_corr_dem_copy).plot()\n",
    "plt.title(glacier[num]+' Difference '+ parameter_name+ ' corrected less uncorrected thickness map (both DEM corrected)')\n",
    "plt.savefig(products+'difference_'+ parameter_name + '_corrected_vs_uncorrected_'+ glacier[num]+'.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
