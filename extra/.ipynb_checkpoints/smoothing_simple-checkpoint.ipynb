{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This notebook \n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from oggm import utils, workflow, tasks, graphics\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import salem\n",
    "import xarray as xr\n",
    "import oggm\n",
    "from oggm.workflow import execute_entity_task, gis_prepro_tasks, climate_tasks\n",
    "\n",
    "import oggm.cfg as cfg # could that cause problems?\n",
    "import gdal\n",
    "from PIL import Image as imagery\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the glacier by setting num to:\n",
    "\n",
    "- 0 for Kokanee\n",
    "- 1 for Haig\n",
    "- 2 for Conrad\n",
    "- 3 for W. Washmawapta (no DEM correction available)\n",
    "- 4 for Illecillewaet (not supported in this version of the script due to shapefile reasons)\n",
    "- 5 for Nordic (not supported in this version of the script due to shapefile reasons)\n",
    "- 6 for Zillmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected:  Conrad\n"
     ]
    }
   ],
   "source": [
    "# Here the num variable is set:\n",
    "num=2\n",
    "\n",
    "# sw = 201. # smoothing window  size in meters (default = 251 m)\n",
    "\n",
    "# fl_smooth = 1 # pixel size of the gaussian smoothing\n",
    "\n",
    "# dfb = 0.25 # the exponent of the distance from border mask default=0.25\n",
    "\n",
    "# # smoothing radius, Default is to use cfg.PARAMS[‘smooth_window’] (i.e. a size in meters). Set to zero to suppress smoothing.\n",
    "# sr = 0 # default is sw / gdir.grid.dx  # so in pixels\n",
    "\n",
    "# A list with all the glacier names\n",
    "glacier = ['Kokanee', 'Haig', 'Conrad', 'Washmawapta', 'Illecillewaet', 'Nordic', 'Zillmer']\n",
    "\n",
    "# Just confirm that the correct one is selected for this run of the script\n",
    "print('You selected: ' , glacier[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File names settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with the names in the Randolf Glacier invetory (according to the glacier names above)\n",
    "rgi_list = ['RGI60-02.00147', 'RGI60-02.01857', 'RGI60-02.02171', 'RGI60-02.03411', 'RGI60-02.03688', 'RGI60-02.04264', 'RGI60-02.07780']\n",
    "\n",
    "# list with the names Lidar data (according to the glacier names above)\n",
    "dem = ['kokanee/20160913_kokanee_dem1_clip_slave.tif', 'haig/20150912_haig_dem_master_clip.tif', 'conrad/20160912_conrad_dem1_clip_slave.tif', 'not_assigned', \n",
    "       'illecillewaet/170917_illecillewaet_dem1_clip_slave.tif', 'nordic/20170927_nordic_dem1_clip_slave.tif', 'zillmer/160914_zillmer_dem2.tif']\n",
    "\n",
    "#products_directory (where the graphs and some numbers are saved for later usage)\n",
    "products= '/home/pelto/oggm_runs/products_opt/test/' # + glacier[num] + '/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A function to run the OGGM using mass-balance correction and (if wished) the Lidar-DEM \n",
    "\n",
    "This is also a function that runs the OGGM on the selected glacier and returns a thickness map for it. It uses the mass-balance correction.\n",
    "\n",
    "In difference to the function above, this version does not use the SRTM DEM to run it but the more precise Lidar DEM which yields results closer to reality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = [29, 32, 68, 23, 49, 36, 46]\n",
    "thick_list = []\n",
    "count = 0\n",
    "\n",
    "def new_mb_grad_corr_dem(num, dem, glacier, name, parameter, best, use_dem_corr):\n",
    "    \"\"\"\n",
    "    :param num: number of selected glacier\n",
    "    :param dem: list with dem file names\n",
    "    :param glacier: the list with the glacier names\n",
    "    :param name: name of the parameter to be modified\n",
    "    :param parameter: value of the parameter to be modified\n",
    "    :param best: if TRUE, an extra save with prefix 'best' will be created\n",
    "    :param use_dem_correction: if TRUE, a Lidar DEM correction will be used\n",
    "    :type num: int\n",
    "    :type dem: str list\n",
    "    :type glacier: str list\n",
    "    :type name: str \n",
    "    :type parameter: float\n",
    "    :type best: boolean\n",
    "    :type use_dem_correction: boolean\n",
    "    :returns: distributed thickness\n",
    "    :rtype: 2D float array\n",
    "    \"\"\" \n",
    "    count = 0   \n",
    "    for i in np.arange(dx[num], 251., 10):\n",
    "\n",
    "        # Initialize OGGM and set up the run parameters --> Read the configuration file containing the run’s parameters.\n",
    "        cfg.initialize(logging_level='WORKFLOW')\n",
    "\n",
    "        #num determines which gdir and gradient to use, refer to list below to select desired site\n",
    "        grad = [6.84, 9.8, 7.11, 7.95, 10.84, 6.01, 7.92] # mm w.e. m-1\n",
    "\n",
    "        sw =  np.arange(dx[num], 251., 10) # smoothing window  size in meters (default = 251 m)\n",
    "        sw = sw[count]\n",
    "        # Get the RGI glaciers for the run.\n",
    "        rgi_list = ['RGI60-02.00147', 'RGI60-02.01857', 'RGI60-02.02171', 'RGI60-02.03411', 'RGI60-02.03688', 'RGI60-02.04264', 'RGI60-02.07780']\n",
    "        rgidf = utils.get_rgi_glacier_entities(rgi_list)\n",
    "\n",
    "\n",
    "        ############################################################# here the DEM correction happens #########################################################\n",
    "\n",
    "        # if(use_dem_corr==True):\n",
    "\n",
    "        custom_dem_path = '/home/pelto/Desktop/lidar_cbt_analysis/' + dem[num]\n",
    "\n",
    "        #     WORKING_DIR2 = utils.gettempdir(glacier[num] + '_lidar_dem_smoothing') # Let's make a working directory for this DEM \n",
    "        #     utils.mkdir(WORKING_DIR2, reset=True)\n",
    "        #     cfg.initialize(logging_level='WORKFLOW')\n",
    "        #     cfg.PATHS['working_dir'] = WORKING_DIR2\n",
    "\n",
    "        cfg.PATHS['dem_file'] = custom_dem_path\n",
    "        rgidf['DEM_SOURCE'] = 'USER'\n",
    "\n",
    "        cfg.PARAMS['smooth_window'] = sw\n",
    "        #     #cfg.PARAMS['grid_dx_method'] = 'fixed'\n",
    "        #     #cfg.PARAMS['fixed_dx'] = dx\n",
    "        #     if glacier[num] == 'Nordic':\n",
    "        #         cfg.PARAMS['use_intersects'] = False\n",
    "        #     gdirs = workflow.init_glacier_regions(rgidf)\n",
    "        #     cfg.PARAMS['use_rgi_area'] = False\n",
    "\n",
    "        cfg.PARAMS['use_intersects'] = True\n",
    "        cfg.PARAMS['border'] = 10\n",
    "        cfg.PATHS['working_dir'] = utils.get_temp_dir('smoothing' + glacier[num])\n",
    "        cfg.PARAMS['use_rgi_area'] = False\n",
    "        # cfg.PARAMS[name] = parameter\n",
    "\n",
    "        ###########################################################################################################################\n",
    "\n",
    "        # cfg.PARAMS[name] = parameter\n",
    "        cfg.PARAMS['border'] = 10\n",
    "        #     cfg.PARAMS['flowline_height_smooth'] = fl_smooth\n",
    "\n",
    "\n",
    "        temporarily = [rgi_list[num]]\n",
    "        rgidf = utils.get_rgi_glacier_entities(temporarily)#[rgi_list[num]]) !!!!!!!!!!!!!!!!!!\n",
    "        gdirs = workflow.init_glacier_regions(rgidf)\n",
    "        workflow.gis_prepro_tasks(gdirs)\n",
    "        workflow.climate_tasks(gdirs)\n",
    "        workflow.inversion_tasks(gdirs)\n",
    "        workflow.execute_entity_task(tasks.distribute_thickness_per_altitude, gdirs); #smooth_radius=sr, , dis_from_border_exp=dfb\n",
    "        gdir = gdirs[0]    \n",
    "        tasks.init_present_time_glacier(gdir) ##This updates the mode_flowlines file and creates a stand-alone numerical glacier ready to run.\n",
    "\n",
    "        # Print the standard MB gradient from OGGM default\n",
    "        from oggm.core.massbalance import ConstantMassBalance, MultipleFlowlineMassBalance\n",
    "        # gdir = gdirs[num]\n",
    "\n",
    "        mb_mod = MultipleFlowlineMassBalance(gdir, use_inversion_flowlines=True, mb_model_class=ConstantMassBalance)\n",
    "        z, w, mb_on_z = mb_mod.get_annual_mb_on_flowlines()\n",
    "        mb_on_z *=  cfg.PARAMS['ice_density'] * cfg.SEC_IN_YEAR\n",
    "\n",
    "        # grad_line = np.polyfit(mb_on_z,z,2)\n",
    "        from scipy import stats \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(mb_on_z, z)\n",
    "        print(\"slope: %f    intercept: %f\" % (slope, intercept), \"  R-squared: %f\" % r_value**2)\n",
    "\n",
    "        # See the result of the inversion\n",
    "        workflow.execute_entity_task(tasks.distribute_thickness_per_altitude, gdirs); #smooth_radius=sr, dis_from_border_exp=dfb\n",
    "\n",
    "        ds_default = xr.open_dataset(gdir.get_filepath('gridded_data')).load()\n",
    "        ds_default.close() # I have the strange feeling that xarray sometimes won't re-read overwitten files (and we will overwrite it later)\n",
    "\n",
    "        ds_default = xr.open_dataset(gdir.get_filepath('gridded_data')).load()\n",
    "        ds_default.close() # I have the strange feeling that xarray sometimes won't re-read overwitten files (and we will overwrite it later)\n",
    "\n",
    "\n",
    "        # Let's apply a linear MB instead\n",
    "        from oggm.core.climate import apparent_mb_from_linear_mb\n",
    "\n",
    "\n",
    "        workflow.execute_entity_task(tasks.apparent_mb_from_linear_mb, gdir, mb_gradient=grad[num]);\n",
    "\n",
    "        from oggm.core.massbalance import LinearMassBalance\n",
    "\n",
    "        params = gdir.read_pickle('linear_mb_params')\n",
    "        print(params)\n",
    "\n",
    "        l_mb_mod = LinearMassBalance(params['ela_h'], grad=params['grad'])\n",
    "        l_mb_on_z = l_mb_mod.get_annual_mb(z) * cfg.PARAMS['ice_density'] * cfg.SEC_IN_YEAR\n",
    "\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(mb_on_z, z)\n",
    "        print(\"slope default: %f    intercept: %f\" % (slope, intercept), \"  R-squared: %f\" % r_value**2)\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(l_mb_on_z, z)\n",
    "        print(\"slope: %f    intercept: %f\" % (slope, intercept), \"  R-squared: %f\" % r_value**2)\n",
    "\n",
    "        ds_new = xr.open_dataset(gdir.get_filepath('gridded_data')).load()\n",
    "        ds_new.close() \n",
    "\n",
    "\n",
    "        ########### gather more detailed information about the glacier ##############\n",
    "        df  = utils.compile_glacier_statistics(gdirs, inversion_only=True)\n",
    "        volume=df['inv_volume_km3']\n",
    "\n",
    "        mfl=gdir.read_pickle('model_flowlines')\n",
    "        thickness= mfl[-1].surface_h - mfl[-1].bed_h\n",
    "        thickness=thickness[thickness>0].mean()\n",
    "\n",
    "        thick_list.append(thickness)\n",
    "        count=count+1\n",
    "    return ds_new, gdir, thick_list\n",
    "\n",
    "        ############## write it into txt file: #################\n",
    "\n",
    "        # if(best):\n",
    "        #     file= open(products+'best_dem_corr_run_of_'+ glacier[num]+'_with_modified_' + name+'.txt', mode='w')\n",
    "        #     # else:\n",
    "        #     file= open(products+'dem_corr_run_of_'+glacier[num]+'_with_modified_' +'.txt', mode='w')\n",
    "\n",
    "        #     file.writelines(['Run of the DEM corrected model on ' + glacier[num]+' on ', str(datetime.datetime.now()), '\\n'])\n",
    "        #     # file.write('parameter modified: '+name+'\\n')\n",
    "        #     # file.write('parameter value: '+str(parameter)+'\\n')\n",
    "        #     file.write('glacier total volume: '+str(volume)+' km^3 \\n \\n \\n')\n",
    "        #     file.write('mean thickness value: '+str(thickness)+' m \\n')\n",
    "        #     file.close()\n",
    "        ##########################################################\n",
    "\n",
    "        # return ds_new, gdir\n",
    "        #ds_new.distributed_thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[ 68.  78.  88.  98. 108. 118. 128. 138. 148. 158. 168. 178. 188. 198.\n",
      " 208. 218. 228. 238. 248.]\n"
     ]
    }
   ],
   "source": [
    "print(thick_list)\n",
    "print(np.arange(dx[num], 251., 10))\n",
    "smooth = np.arange(dx[num], 251., 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0cd5246ce6b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthick_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/oggm_env/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[1;32m   2862\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m         verts=verts, edgecolors=edgecolors, **({\"data\": data} if data\n\u001b[0;32m-> 2864\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2865\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2866\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/oggm_env/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda2/envs/oggm_env/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   4180\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4182\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(thick_list, smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing DEM-corrected model with non-DEM-corrected model:\n",
    "\n",
    "- first we run the 'new_mb_grad' function\n",
    "- then we run the 'new_mb_grad_corr_dem' function\n",
    "- and then we subtract the thickness maps and can see where the usage of Lidar data actually impacted the outcome of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run the model without DEM correction\n",
    "# new_mb_gradient = new_mb_grad_corr_dem(num, dem, glacier, 'ice_density', 900, False, False)\n",
    "\n",
    "# # plot it as a map\n",
    "# new_mb_gradient_thick = new_mb_gradient[0].distributed_thickness\n",
    "# new_mb_gradient_thick.plot()\n",
    "# plt.title(glacier[num]+' standard settings thickness map')\n",
    "# # and save it\n",
    "# plt.savefig('/home/pelto/Desktop/ice_thick/products'+'standard_map_'+ glacier[num]+'.png', dpi=100)\n",
    "\n",
    "# # replace 'nan' by  0\n",
    "# new_mb_gradient_thick=new_mb_gradient_thick.fillna(0)\n",
    "\n",
    "# if glacier[num]=='Washmawapta':\n",
    "#     # make a copy for comparison reasons later on\n",
    "#     new_mb_gradient_corr_dem=new_mb_gradient_thick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model with DEM correction\n",
    "new_mb_gradient_corr_dem = new_mb_grad_corr_dem(num, dem, glacier, 'ice_density', 900, False, True)\n",
    "# will fail with HDF error if ds_new.close() isn't run\n",
    "\n",
    "new_mb_gradient_corr_dem_thick = new_mb_gradient_corr_dem[0].distributed_thickness\n",
    "# plot it as a map\n",
    "new_mb_gradient_corr_dem_thick.plot()\n",
    "plt.title(glacier[num]+' DEM corrected Thickness map')\n",
    "\n",
    "# and save it\n",
    "plt.savefig(products+'dem_corr_standard_map_'+ glacier[num]+'.png', dpi=100)\n",
    "\n",
    "# replace 'nan' by  0\n",
    "new_mb_gradient_corr_dem_thick=new_mb_gradient_corr_dem_thick.fillna(0)\n",
    "\n",
    "# make a copy for comparison reasons later on\n",
    "new_mb_gradient_corr_dem_copy = new_mb_gradient_corr_dem_thick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(thick_list)\n",
    "print(np.arange(dx[num], 251., 10))\n",
    "smooth = np.arange(dx[num], 251., 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # the actual differencing and plotting\n",
    "# (new_mb_gradient_corr_dem_thick-new_mb_gradient_thick).plot()\n",
    "\n",
    "# # label it, save it\n",
    "# plt.title(glacier[num]+' Difference DEM corrected thickness less standard DEM')\n",
    "# plt.savefig(products+'difference_dem_correction_'+ glacier[num]+'.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter optimization\n",
    "\n",
    "We want to run the Model with different values for a certain parameter. Therefore we define a few functions that will iterate over a sequenze of paramter values and allow us to compare the outcome to the observation data by displaying their respective squared residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_parameter(num,dem, glacier, name, parameter):\n",
    "    \"\"\"\n",
    "    :param num: number of selected glacier\n",
    "    :param dem: list with dem file names\n",
    "    :param glacier: the list with the glacier names\n",
    "    :param name: name of the parameter to be modified\n",
    "    :param parameter: value of the parameter to be modified\n",
    "    :type num: int\n",
    "    :type dem: str list\n",
    "    :type glacier: str list\n",
    "    :type name: str \n",
    "    :type parameter: float\n",
    "    :returns: distributed thickness\n",
    "    :rtype: 2D float array\n",
    "    \"\"\"\n",
    "    \n",
    "    # just to be 100% sure, we are setting the most common parameters to their presettings in order to only vary the desired parameter\n",
    "    \n",
    "    cfg.PARAMS['ice_density'] = 900\n",
    "    cfg.PARAMS['trapezoid_lambdas'] = 0.2\n",
    "    cfg.PARAMS['mixed_min_shape'] = 0.001\n",
    "    cfg.PARAMS['downstream_min_shape'] = 0.0001\n",
    "    cfg.PARAMS['mu_star_halfperiod'] = 15\n",
    "    cfg.PARAMS['tstar_search_glacierwide'] = False\n",
    "    cfg.PARAMS['border'] = 10\n",
    "    cfg.PARAMS['glen_a'] = 2.4e-24\n",
    "    cfg.PARAMS['inversion_glen_a'] = 2.4e-24\n",
    "    cfg.PARAMS['default_parabolic_bedshape'] = 0.003\n",
    "    cfg.PARAMS['use_shape_factor_for_fluxbasedmodel'] = ''\n",
    "    \n",
    "    #change the parameter (not sure, whether it has any effect here...)\n",
    "    cfg.PARAMS[name] = parameter\n",
    "\n",
    "    # run the model (in this case with DEM correction)\n",
    "    outcome=new_mb_grad_corr_dem(num, dem, glacier, name, parameter, False, use_dem_correction)[0].distributed_thickness.fillna(0)\n",
    "    #return the thickness distribution\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# deletes the rows and lines that do only carry zeros for the sake of getting the right resolution \n",
    "# in order to rasterize the observation data to the same resolution and getting perfectly fitting arrays\n",
    "def delete_nodata(data):\n",
    "    \"\"\"\n",
    "    :param data: distributed thickness with 'nan' or '0' in it\n",
    "    :type data: 2D floar array\n",
    "    :returns: distributed thickness\n",
    "    :rtype: 2D float array\n",
    "    \"\"\"\n",
    "    \n",
    "    # get a numpy array out of it\n",
    "    data=data.values\n",
    "\n",
    "    #get the spots were actual values are\n",
    "    coordinates=np.nonzero(data)\n",
    "    \n",
    "    # create a fresh array of the minimal shape to contain all non-zero values\n",
    "    result=np.zeros(((1+np.max(coordinates[0])-np.min(coordinates[0])) ,(1+np.max(coordinates[1])-np.min(coordinates[1]))))\n",
    "\n",
    "    # fill it with the values\n",
    "    for i in range(0, len(coordinates[0])):\n",
    "        result[coordinates[0][i]-np.min(coordinates[0])][coordinates[1][i]-np.min(coordinates[1])]=data[coordinates[0][i]][coordinates[1][i]]\n",
    "    \n",
    "    # flip it and rotate it by pi\n",
    "    return np.flip(np.rot90(result,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple function to open the observation data and return it as an array\n",
    "def read_obs_data(path):\n",
    "    \"\"\"\n",
    "    :param path: distributed thickness with 'nan' or '0' in it\n",
    "    :type path: str\n",
    "    :returns: measurement points as an array\n",
    "    :rtype: 2D float array\n",
    "    \"\"\"\n",
    "    src_obs = gdal.Open(path)\n",
    "    return src_obs.ReadAsArray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We open the observation data for the respective glacier and print out the shape and compare it with the shape of the OGGM:\n",
    "\n",
    "obs_data = read_obs_data('/home/pelto/oggm_runs/OGGM/MONSTER_project/MONSTER/obs_data_' + glacier[num] + '.tif')\n",
    "\n",
    "if obs_data.shape == delete_nodata(new_mb_gradient_corr_dem_thick).shape:\n",
    "    print('Fantanstic, both arrays have the same shape of: ' ,obs_data.shape )\n",
    "else:\n",
    "    print('Oh, Oh! Something went wrong because the observation data has the shape ' ,obs_data.shape , ' and the OGGM out put has a shape of: ' ,delete_nodata(new_mb_gradient_corr_dem).shape )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layover-Control\n",
    "\n",
    "This is a checking tool for adjusting the orientation of the observation data with respect to the model shapefile (in order to make it fit, we had to flip and rotate it in the 'delete_nodata' function). The resolution is not great but is should give an optical feedback on the fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the delete_nodata function on one of the recent outputs and save it in a temporay variable\n",
    "temp=delete_nodata(new_mb_gradient_corr_dem_thick)\n",
    "\n",
    "# get its shape\n",
    "h,w = temp.shape\n",
    "\n",
    "# create a new array with zeros and of same size\n",
    "data = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "\n",
    "# and get the data point coordinates\n",
    "nonzero=np.nonzero(temp)\n",
    "\n",
    "# run through the OGGM output and write into the array as RED color code\n",
    "for i in range(0,len(nonzero[0])):\n",
    "    data[nonzero[0][i]][nonzero[1][i]]= [temp[nonzero[0][i]][nonzero[1][i]], 0, 0]\n",
    "    \n",
    "# run through the observation data and write into the array as GREEN color code\n",
    "for i in range(0,len(np.nonzero(obs_data)[0])):\n",
    "    data[np.nonzero(obs_data)[0][i]][np.nonzero(obs_data)[1][i]]= [0, obs_data[np.nonzero(obs_data)[0][i]][np.nonzero(obs_data)[1][i]], 0]\n",
    "    \n",
    "# save and show\n",
    "img = imagery.fromarray(data, 'RGB')\n",
    "img.save(products+ 'overlay_test_'+ glacier[num]+ '.tif')\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename=products+'overlay_test_'+ glacier[num]+ '.tif', width=400) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Error\n",
    "\n",
    "\n",
    "We want a function that gives us the accumulated quadratic residuals of the observation data compared to the OGGM output. Because we may have very few points that are assigned a measurement but do not locate on the OGGM glacier, we have to do a little extra: We count those pixels, print their share on the entire quadratic errors and subtract their errors from the result in order not to confuse the optimization process later on. However, their share usually is below 1-2% - their impact therefore limited. This is only done for checking and consistency reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_errors(obs_data, mesharray):\n",
    "    \"\"\"\n",
    "    :param obs_data: array with measured values on respective spots\n",
    "    :param mesharray: distributed thickness of the model output (should have same shape as obs_data)\n",
    "    :type obs_data: 2D float array\n",
    "    :type mesharray: 2D float array\n",
    "    :returns: quadrativc error (problems corrected)\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    \n",
    "    # counts number of \"problematic\" pixels\n",
    "    count=0\n",
    "    \n",
    "    # coordinates of the data points\n",
    "    coordinates=np.nonzero(obs_data)\n",
    "    \n",
    "    # accumulated 'problematic pixel' quadratic error\n",
    "    problems=0\n",
    "    \n",
    "    # total accumulated quadratic error\n",
    "    err=0\n",
    "\n",
    "    # we go through all the measured points and accumulate the squared differences to the OGGM at that point\n",
    "    for i in range(0,len(coordinates[0])):\n",
    "        \n",
    "        # if however, the OGGM shows a thickness of zero there, this seems to be a \"problematic\" pixel \n",
    "        if mesharray[coordinates[0][i]][coordinates[1][i]]==0:\n",
    "            \n",
    "            # add to problems share\n",
    "            problems=problems+obs_data[coordinates[0][i]][coordinates[1][i]]**2\n",
    "            \n",
    "            # increment problem number\n",
    "            count=count+1\n",
    "        \n",
    "        # add squared difference\n",
    "        err=err+(obs_data[coordinates[0][i]][coordinates[1][i]]-mesharray[coordinates[0][i]][coordinates[1][i]])**2\n",
    "   \n",
    "    # outprint of details on \"problematic\" pixels\n",
    "    print('found ', count , ' problem(s) within a total number of data point of: ', len(coordinates[0]), ' problem share ', problems/err,)\n",
    "    \n",
    "    print('corrected quadratic error is: ', err-problems)\n",
    "    return (err-problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that runs the (DEM-corrected) OGGM and uses the quadratic_errors function to return the quadratic errors\n",
    "def master_analysis(name, parameter, obs_data, glacier, num):\n",
    "    \"\"\"\n",
    "    :param name: name of the parameter to be modified\n",
    "    :param parameter: value of the parameter to be modified\n",
    "    :param obs_data: measured data points\n",
    "    :param glacier: the list with the glacier names\n",
    "    :param num: number of selected glacier\n",
    "    :type name: str\n",
    "    :type parameter: float\n",
    "    :type obs_data: 2D float array\n",
    "    :type glacier: str list\n",
    "    :type num: int\n",
    "    :returns: quadratic errors\n",
    "    :rtype: float\n",
    "    \"\"\"\n",
    "    quadmesh= run_with_parameter(num, dem, glacier, name, parameter)\n",
    "    mesharray = delete_nodata(quadmesh)\n",
    "    \n",
    "    return quadratic_errors(obs_data, mesharray)\n",
    "\n",
    "# this function takes in the name of the parameter that is to be modified and a float list of the values for whose the OGGM is \n",
    "# to be run and the quadratic errors to be calculated. It returns an array with those values and their respective quadratic errors\n",
    "def optimize(name, values, obs_data, glacier, num):\n",
    "    \"\"\"\n",
    "    :param name: name of the parameter to be modified\n",
    "    :param values: values of the parameter to be modified\n",
    "    :param obs_data: measured data points\n",
    "    :param glacier: the list with the glacier names\n",
    "    :param num: number of selected glacier\n",
    "    :type name: str\n",
    "    :type values: float list\n",
    "    :type obs_data: 2D float array\n",
    "    :type glacier: str list\n",
    "    :type num: int\n",
    "    :returns: [values, quad_errors]\n",
    "    :rtype: float array\n",
    "    \"\"\"\n",
    "    \n",
    "    # here we store the original parameter value\n",
    "    temp= cfg.PARAMS[name]\n",
    "    \n",
    "    #an array to store the quadratic errors in\n",
    "    quad_errors=[]\n",
    "    for i in range(0,len(values)):\n",
    "        quad_errors.append(master_analysis(name, values[i], obs_data, glacier, num))\n",
    "        \n",
    "    # and here we reset it to the default value\n",
    "    cfg.PARAMS[name] = temp\n",
    "    \n",
    "    return [values, quad_errors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter the parameter, interval and number of points that you want to get the quadratic error from \n",
    "\n",
    "The parameter intervall will be a linearly spaced sequence from min_value to max_value with number_of_steps steps.\n",
    "\n",
    "Also, choose, whether you prefer to run the iteration with the DEM correction. In the most cases it is strongly recommended to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_name='inversion_glen_a'\n",
    "max_value=0.1e-24\n",
    "min_value=54e-24\n",
    "number_of_steps=10\n",
    "\n",
    "use_dem_correction=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual iteration takes place here\n",
    "\n",
    "%%capture supresses the output, which is quite annoying if the OGGM runs several dozen times. But if you want to watch it work, go for it and delete that line.\n",
    "\n",
    "Apart from that, we basically run the optimize function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "to_plot=optimize(parameter_name,np.linspace(min_value, max_value, number_of_steps), obs_data ,glacier, num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot the quadratic errors as a function of the parameter values. We also print out the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams['axes.titlepad'] = 30\n",
    "plt.plot(to_plot[0],to_plot[1],linestyle='--', marker='o', color='b')\n",
    "plt.xlabel('value of '+parameter_name)\n",
    "plt.ylabel('pointwise accumulated quadratic discrepancies [m²]')\n",
    "plt.title('Quadratic errors of depth in dependence of ' +parameter_name)\n",
    " \n",
    "# save it\n",
    "plt.savefig(products+'quadratic_errors_'+parameter_name+'_from_'+str(min_value)+'_to_'+str(max_value)+'_'+ glacier[num]+'.png', dpi=100)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#small minimum function\n",
    "x=0\n",
    "for i in range(0,len(to_plot[1])):\n",
    "    if to_plot[1][i]==np.min(to_plot[1]):\n",
    "        x=i\n",
    "\n",
    "# print out\n",
    "print('Minimal value is '+str(np.min(to_plot[1]))+ ' at ' + parameter_name+' = ' +str(np.round(to_plot[0][x],decimals=28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep analysis of best parameter value\n",
    "\n",
    "Enter the value of the given Paramter, that yields a minimum in quadratic errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the minimum from above\n",
    "best_value=to_plot[1][x]\n",
    "\n",
    "# select it manually\n",
    "best_value = 6.740e-24, 0.774e-24, 8.095e-24, 0.142e-24, 4.050e-24, 0.130e-24, 3.810e-24  \n",
    "best_value = best_value[num]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we run the model with the best parameter value to create seperate saves and a deep analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = new_mb_grad_corr_dem(num, dem, glacier, parameter_name, best_value, True, False) \n",
    "#will fail with HDF error if ds_new.close() isn't run\n",
    "\n",
    "best_dist_thick = best_model[0].distributed_thickness\n",
    "best_dist_thick.plot()\n",
    "plt.title(glacier[num]+' best approximation thickness map ' + parameter_name + ' = ' +str(best_value))\n",
    "plt.savefig(products+'dem_corr_best_map_'+ glacier[num]+'.png', dpi=100)\n",
    "#best_model=new_mb_gradient_corr_dem.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot and save\n",
    "(best_dist_thick-new_mb_gradient_corr_dem_copy).plot(cmap='RdBu', vmin=-100, vmax=100)\n",
    "plt.title(glacier[num]+' Difference '+ parameter_name+ ' corrected less uncorrected thickness map (both DEM corrected)')\n",
    "plt.savefig(products+'difference_'+ parameter_name + '_corrected_vs_uncorrected_'+ glacier[num]+'.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save binned thickness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binned_thickness(file_location):\n",
    "    dem = best_model[0]['topo']\n",
    "    thick = best_model[0]['distributed_thickness']\n",
    "\n",
    "    # convert 2-d elevation and SWE arrays to 1-D vectors using ravel function\n",
    "    Zvec = np.ravel(dem)\n",
    "    Depthvec = np.ravel(thick)\n",
    "    # Velvec = np.ravel(vel)\n",
    "\n",
    "    bins = range(1400,3700,100)#(1400,3700,10) \n",
    "\n",
    "    df = pd.DataFrame({\"Z\":Zvec,\"Depth\":Depthvec})\n",
    "\n",
    "    # classify the elevation data into 100 metre bins and add to the data frame \n",
    "    df['Zbins'] = pd.cut(df['Z'], bins, labels= np.arange(1450, 3650, 100))#(1405, 3695, 10))  #\n",
    "\n",
    "    ## get some statistics from the data\n",
    "    ## this will be series which can be a pain to work with \n",
    "    ## so convert to dataframes\n",
    "    mean = df.groupby(by='Zbins')['Depth'].mean()\n",
    "    iqr    = df.groupby(by='Zbins')['Depth'].quantile(0.75) - df.groupby(by='Zbins')['Depth'].quantile(0.25)\n",
    "    count  = df.groupby(by='Zbins')['Depth'].count()\n",
    "\n",
    "    ## remove any values that are less than 100 values\n",
    "    ## these are series not pandas dataframes\n",
    "\n",
    "    ## convert series to pandas data frames instead of series\n",
    "\n",
    "    mean = mean.to_frame() \n",
    "    iqr    = iqr.to_frame()\n",
    "    count  = count.to_frame()\n",
    "\n",
    "    ## Make combine data frame\n",
    "\n",
    "    mean['iqr']   = iqr\n",
    "    mean['count'] = count\n",
    "\n",
    "    # ## remove any rows where count is below set threshold\n",
    "    # mean[mean['count'] < n_min] = np.nan\n",
    "\n",
    "    mean = mean.dropna()\n",
    "\n",
    "    ## reset index to make Zbins a column rather than an index\n",
    "    mean          = mean.reset_index()\n",
    "    mean['Zbins'] = mean['Zbins'].tolist()\n",
    "\n",
    "    # ## returns data frame \n",
    "    # return mean \n",
    "    mean.to_csv(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_thickness('/home/pelto/Desktop/ice_flux/' + glacier[num] + '_optimized_thickness_binned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_along_glacier(nx, map_dx):\n",
    "    \"\"\"Calculates the distance along the glacier in km.\n",
    "    Parameters\n",
    "    ----------\n",
    "    nx : int\n",
    "        number of grid points\n",
    "    map_dx : int\n",
    "        grid point spacing\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        distance along the glacier in km.\n",
    "    \"\"\"\n",
    "    return np.linspace(0, nx, nx) * map_dx * 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot profile glacier bed and surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_profiles(): \n",
    "    gdir = best_model[1]\n",
    "    mfl=gdir.read_pickle('model_flowlines')\n",
    "    bed_h = mfl[-1].bed_h\n",
    "    surface_h = mfl[-1].surface_h\n",
    "    length_m = mfl[-1].length_m\n",
    "\n",
    "    nx = len(bed_h)\n",
    "    # length_m\n",
    "    map_dx = int(gdir.grid.dx * cfg.PARAMS['flowline_dx'])\n",
    "    # calculate the corresponding distance along the glacier (from the top)\n",
    "    dist_along_glacier = distance_along_glacier(nx, map_dx) # in km \n",
    "\n",
    "    size = 4\n",
    "    fig, ax = plt.subplots(figsize=[size*2,size])\n",
    "    ax.plot(dist_along_glacier, surface_h, label='Glacier surface', color='#9ecae1', linewidth=1, alpha=0.8)\n",
    "    ax.plot(dist_along_glacier, bed_h,  label='Bed', color='k', linewidth=1, alpha=0.8)\n",
    "    ax.set_xlabel('Distance along glacier (km)')\n",
    "    ax.set_ylabel('Elevation [m a.s.l.]')\n",
    "    # ax.set_title(gdir.rgi_id)\n",
    "    # ax.grid(True)\n",
    "    # ax.legend();\n",
    "    plt.tight_layout(pad=0.5)\n",
    "    fig.savefig(products + glacier[num] + str(size) + 'in_profile.tiff', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_profiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export NetCDF of ice thickness data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model[0].to_netcdf(products + glacier[num] + '_optimized.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
